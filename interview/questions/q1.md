### 自我介绍

- 05年计算机系毕业后开始接触软件测试
- 较早接触到自动化测试，性能测试等测试开发方面的工作
- 过去几家公司中，有较多项目经验，涉及到各种企业应用
- 目前带领4人测试开发组
- 主要负责自动化测试框架的设计开发和性能测试方面的工作
- 对测试流程，测试管理，测试方法等都有较深的实践和体会
- 有基于 QC/UFT 和 TestNG/Selenium 开源框架开发经验
- 开发测试服务器，测试工具经验，开发监控系统
- 编程语言熟悉 python，java
- 熟悉 Linux，mysql
- 个人优势：T 字形知识架构。除了对测试技术了解外，对各类常见开发应用，技术均有了解，有一定开发能力，对新事务上手快。



### 如何写测试计划，包含哪些部分

* 测试目标。根据商业目标，质量目标，制定测试计划

  * 质量目标 - 依据产品商业价值，对公司业务重要度不同，测试目标不同
    * 对业务重要的系统要求质量第一（0 bug 上线）。要求线上事故率，无 p0和p1级事故。
    * 对不那么重要的系统，快速上线
    * 项目铁三角，时间，成本，质量
  * 需求分析。关注测试优先级，测试重点，难点，关键路径
    * 以思维导图形式，初步梳理模块，每个模块内功能。
    * 根据业务场景梳理功能关键路径
    * 按功能优先级划分（主要功能，次要功能）
    * 功能于功能之间强关联功能，弱关联功能

  * 测试策略

    * 整体测试策略
      * 多样性测试：业务场景，交互，UI，兼容性，数据逻辑，业务逻辑，性能测试，尽可能发觉问题。
      * 组内组外充分沟通，发掘关注盲区
    * 版本测试策略，测试颗粒度
      * P1重点功能，充分分析业务场景，测试用例详细设计，然后进行探索式测试
      * P2主要功能，测试用例详细设计，不需要探索式测试
      * P3次要功能，仅编写测试要点，进行探索式测试
      * P4一般功能，根据需求文档进行测试

  * 制定计划

    * 在测试之前安排测试用例编写，测试用例评审
    * 工期，人员资源安排 
      * 根据模块，任务量人天分配任务到每个人，设置里程碑
    * 分阶段测试：
      * 开发接口提测时间
      * 分模块提测时间
      * 开发整体提测时间
    * 风险处理
      * 预先识别的风险，指定风险策略
      * 资源，时间，成本估算时要留有余地
      * 关键性岗位要有后备人员
      * 文档完整，及时，便于知识分享和移交
        * 测试日志，版本控制文档，整体技术文档（测试策略，测试用例）
      * 相互评审，不同人员交叉测试
      * 跟踪工作过程，及时发现风险迹象。

    **1、需求风险**

    产品需求的不明确，对产品需求理解不准确，导致测试范围存在误差，遗漏部分需求或者执行了错误的测试方式；另外需求变更导致测试用例变更，测试用例维护成本增加，实时更新时存在误差。

    **2、测试用例风险**

    测试用例设计不完整，忽视了边界条件、异常输入等情况，用例覆盖率没有做到足够覆盖，测试用例没有得到全部执行，有些用例被有意或者无意的漏测，需求变更导致的测试时间被压缩等情况。

    **3、缺陷风险**

    某些缺陷偶发，难以重现，容易被遗漏；缺陷跟踪不够积极主动，没做好缺陷记录和及时更新，同样的缺陷，导致的原因可能不同，对这点没意识到导致的线上生产问题等。

    **4、代码质量风险**

    代码质量差，可读性差，重构性差，没做好注释等原因导致缺陷较多，修改难度增大；另外还有系统架构设计的不足，导致的扩展性不足，性能兼容差等问题。

    **5、测试环境风险**

    测试环境和生产环境配置不同，测试环境交叉影响较大，测试环境数据量不足导致的测试结果误差等问题。

    **6、测试技术风险**

    某些项目存在技术难度，测试能力和经验所限，技术水平相对较差导致测试进展缓慢，测试结果准确性不够，项目发布日期延期等问题。

    **7、回归测试风险**

    回归测试，一般时间相对来说较少，且大多只回归主要的功能点用例，可能造成漏测；另外还有回归验证缺陷时业务流走不通导致的打回修复再验证造成的时间延后问题。

    **8、沟通协调风险**

    项目进行过程中需要多方沟通协调，不同部门，岗位之间的沟通、协作，难免存在误解、沟通不畅的情况，比如需求变更没有及时沟通，开发代码提交没有及时告知，测试结果的反馈不及时等问题。

    **9、研发流程风险**

    其中包括从产品需求评审、研发设计、代码提交、测试发布等一些列流程，流程的不规范不协调很可能导致很多问题；比如开发在不告知其他成员的情况下提交代码，发布没有预生产环境，生产出现

    问题无法及时回滚等很多说烂了的情况。流程没必要一板一眼的执行，但没有流程是万万不行的。

其中有的风险是难以避免的，如缺陷风险；有的风险从理论上可以避免，如需求风险，沟通风险等；还有些风险在实际操作过程中出于时间和成本的考虑，也难以完全回避，如回归测试风险等。

对于这些风险的存在，要尽量避免，也要做好备份方案和容灾机制，规范流程，明确职责，尽可能将风险降到可接受范围内



### 如何做接口测试

* 接口文档：地址，参数类型，方法，输入，输出
* 识别接口类型，对内接口，对外接口
* web service （xml），http （json）
* 测试系统安全性，稳定性，性能。接口会绕过 UI 限制，传入非法内容。
  * 业务功能（正常，异常场景）
  * 业务规则（覆盖度）
  * 参数验证（边界）
  * 异常场景（重复提交，并发提交，事务中断，大数据量）
  * 性能测试（响应时间，吞吐量，并发数，资源要求）
  * 安全测试（权限验证，SQL 注入）
* 检查重点
  * 模拟客户端发送请求报文，服务器接收报文后做处理并返回应答。
    * 基本测试：针对基本业务功能测试，返回数据与预期是否一致
  * 检查数据交互，传递过程，处理次数
  * 接口容错性
  * 参数边界值（+1，-1，null，超长）
    * 边界分析测试：跳过 UI 限制，可覆盖范围广。出现问题概率高
  * 接口性能
    * 性能测试：响应时间，并发，服务端资源使用。需另外单独做。
  * 安全性，尤其对外部调用
* 自动化持续集成，相对于 UI 自动化更稳定。减少回归测试的人力成本和时间
  * 工具：postman，jmeter，java+httpclient，python+request

### 如何做质量管理



### 开发，测试，冲突管理

一、问题确认与评估

再次论证该问题确实是程序缺陷，并评估该缺陷的重要程度并对其分类。比如可存在以下分类：

1、设计文档范围内的功能性缺陷

2、影响到程序的安全性和稳定性缺陷

3、界面缺陷

4、一般性错误（如未考虑边界检查等）

5、边缘死角，规律不明显，不太容易重现的错误

6、兼容性错误（例如旧机型、CPU\MEM,旧标准等等）

7、安全性或易用性等的修改建议

二、明确Dev不修改该缺陷的确切原因

比如可存在以下原因：

1、规律不明显，不好重现

2、dev认为是不影响主要功能的一般性bug,因时间处于版本的稳定期，担心牵一发动全身引起更多错误

3、调用了第三方组件或库函，是第三方程序存在的缺陷

4、存在技术难点

5、设计本身存在问题，程序逻辑是正确的，但实现结果并非用户所需（换言之，dev说这是设计问题，不是程序问题）

6、Dev的个人主观意见：

·该瑕疵可以容忍，没必要修改

·修改该瑕疵会引起更大的问题

7、Tester和dev对错误的理解有分歧：

·tester理解错误，该问题并不是bug

·tester没有说服dev这是个bug

三、具体问题具体分析

分析完第一、二步之后，也就基本上明确了问题的争议焦点，然后具体问题具体分析。

1、如果dev认为不好重现，则tester有责任和义务找到更简洁有效的重现规律。

2、如果tester没有说服dev认识到这是个缺陷，则需要拿出强有力的证据（测试用例、设计文档、错误现象等）来证明。

3、对于第三方库函bug,或技术难点导致的bug,则坚持原则--宁缺勿滥，必要时宁可封掉该功能。

4、针对错误的设计、不能说服的dev主观理解、改动隐患，以及稳定期等特殊情况，则可通过TM进行多方沟通。

四、发挥TM与PM的沟通职责

强调沟通

TM和PM有团队沟通的职责。在bug分类、指派和反馈过程中出现有争议的问题时，TM和PM有责任和义务进行干预。根据问题的重要程度和轻重缓急，采取不同的方式进行沟通。如出现“三”中3、4类较大争议的问题，可通过会议研讨等形式召集多方进行论证，并达成一致的解决意见，解决方法形成备忘录。

对因各种原因继续保留在发布版本中的bug,尤其可能影响功能的，应予以说明，提醒用户绕过。



### 团队管理

### jenkins 主从配置

### 为什么喜欢做测试

### 为什么喜欢做自动化测试

### 为什么喜欢做性能测试

### jvm 架构，如何监控

### Linux 如何监控

### 排序，时间复杂度

### 读文件，写文件

### Springboot 优缺点



### 性能测试项目SAP

订单系统，SAP ECC，仓库管理系统，联合测试

#### S：Situation——事情发生的背景是什么？

SAP 系统上线，连接前端订单系统，后端仓库管理系统，在业务最繁忙时段的性能能否符合要求。

#### T：Target——你的任务/目标是什么？

多个系统联合测试

多系统性能监控

性能调优

#### A：Action——针对这一目标，你采取了何种行动/策略？

每个系统选取重点功能，按业务流程，串联起测试场景。

- Quoting：客户询价，下多种订单，和 SAP 交互包括，物料查询，价格引擎，订单生成
- SAP：保存订单，生成采购需求单，采购订单，入库，发货单
- RP：依据发货单，生成拣货单，拣货，包装，运输
- SAP：发货，会计凭证，生成发票

基于 HTTP，Socket，SAP，QTP，四种协议，编写测试脚本

测试数据准备：测试数据用 mysql 管理，多张表管理不同系统生成的数据，状态，在脚本中使用

使用 python，监控测试状态：在线用户数，脚本日志，每个系统的交易量

监控：

* 网络传输量
* 每个步骤的响应时间
* 每台服务器资源利用率
* 系统错误日志
* 数据库监控
  * 锁
  * top SQL

#### R：Result——最终收获的结果是什么？

 脚本问题：

* 测试帐号不够，导致脚本异常出错。存储过程，取测试帐号。python 监控在线用户，和错误日志。

系统性能问题：

* 数据库锁，导致前台超时，报错。优化程序，缩短锁
* 数据库索引优化，提高查询速度
* 前台采用 GZIP，压缩传输数据量，从几 M 缩小到几 k



### 接口测试项目 SAML

#### 背景

单点登录系统上线，公司内系统多，每个系统都需测试。

没有测试环境，系统未准备好，测试窗口短

#### 目标

测试公司内所有系统正确接入

#### Action

使用 Springboot 开发模拟测试服务器。模拟SAML 流程

* 身份验证（是否合法用户）
* 发送请求至ID provider，IDP 查询 AD
* 返回用户权限等信息

被测系统未准备好，需提前准备好脚本。

Springboot：

* RESTful controller 模拟 get post 请求
* 根据接口文档，准备每个系统的响应模板
* 解析 URL，查询 AD，返回结果

#### 结果

基于模拟服务器，开发了约20个系统的脚本，完成了接口测试

### 订单系统性能测试

#### 背景

对外系统，信息加密

#### 目标

开发中间服务器，解密，替换参数，加密

#### Action

* 调研源码，了解加密解密过程
* 开发 Node.js 服务器，完成解密，加密，正则表达式替换参数列表
* 请求内容，需要替换的数据，发送至中间服务器，服务器依规则替换参数，加密，返回内容
* 发送加密内容至应用服务器
* 开发完成了脚本
* 实施了性能测试，压力测试，并发测试
* 批处理测试
  * 开发 Python 工具，调取处理时间，保存结果

#### 结果

* GC 问题
  * GC 日志
* 内存泄露问题
  * JVM 监控堆内存
* 响应时间慢
  * 优化 SQL 调用

### 性能测试 SAP web service

#### 背景

从 SAP web service 中调取数据，针对SAP web service 性能测试，得出处理能力

SAP 没有开放外部接口，需要调用 pyRFC 包连接

#### 目标

使用 Locust 框架，开发测试脚本

#### Action

* 

#### 监控

* 响应时间
* 并发数

### 自动化测试框架

#### 背景

重构 QTP 测试框架

#### 目标

为一般测试人员开发一个容易使用的测试框架，接近自然语言。

#### Action

* 采用面向对象设计模式，把元素，行为和检查封装起来，
* 数据驱动设计，测试数据和测试类分离
* 分为驱动层 - 封装各个浏览器的驱动
* 基类封装 - 针对网页操作，封装元素定位，基本配置等
* 测试类，封装元素和动作，及关联类
* 元素库
* 测试数据工具类，通用工具类：

### 自动化测试框架 Naveen

测试用例互相独立

* 基类

  * WebDriver driver = new ChromeDriver()
  * load properties
  * 初始化动作
    * 最大化窗口
    * pageloadtimeout
    * implicitwait
    * deleteAllCookies
    * get(url)

* 页面对象库（继承基类）

  * 登录页面
    * 页面元素
    * 动作/方法
      * 初始化
      * 抓取 title
      * 抓取图片
      * login(username, password)
        * return HomePage()
  * 主页
  * 注册页
  * 搜索页
  * 结算

* 测试层（继承基类）
  * 登录页面

    * @BeforeMethod

      * setup()
        * 初始化
        * loginPage = new LoginPage()

    * @AfterMethod

      * driver.quit()

    * 校验 title

    * @DataProvider

    * ```java
      public Object[][] getTestData() {
        Object.data[][] = TestUtil.getTestData(sheetname);
        return data;
      }
      
      @Test(priority = 4, dataProvider = "getTestCata")
      public void validateCreateContact(String title, String, firstName...)
      ```

    * 

  * 主页

  * 注册页

  * 搜索页

  * 结算

* 环境配置
  * 测试环境（url）
  * 测试帐号
  * 浏览器配置
* 测试数据
  * apache.poi
  * xls
* 工具类
  * 截图
    * 截图比对
  * 发邮件
  * 通用方法

* 报告
  * html
  * tesgNG
  * xml

```java
public class WebEventListener extends TestBase implements WebDriverEventListener {
  public void beforeNavigateTo(String url, WebDriver, driver) {
    
  }
  
  public void beforeChangeValueOf(WebElement ...)
  public void beforeClickOn(...)
}
```

TestBase.java

```java
e_dirver = new EventFiringWebDriver(driver);
eventListener = new WebEventListener();
e_driver.register(eventListener);
driver = e_driver;
```



* src/main/resources
  * testng.xml

```xml
<suite name="">
  <listeners>
  	<listener class-class="com.qa.ExtentReporterListener.ExtentReporterNG"></listener>
  </listeners>
	<test name="">
  	<classes>
    	<class name=""></class>
      <class name=""></class>
    </classes>
  </test>
</suite>
```



* 
* log4j

![](https://github.com/Nickyzj/mynotes/blob/master/screenshots/Screen%20Shot%202019-07-30%20at%205.37.22%20PM.png?raw=true)

* extent report
* jenkins
* git
* selenium grid - 并行测试
* 